{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surveil — Weapon Detector Training\n",
    "Trains YOLO11n on real 1920×1080 CCTV footage (Pascal VOC XML annotations).\n",
    "\n",
    "**Dataset:** `frankmurphy24/cctv-weapon-detector` (Images/ folder)  \n",
    "**Classes:** `gun` (Handgun), `rifle` (Short_rifle), `knife` (Knife)  \n",
    "**Output:** `/kaggle/working/runs/weapon/train/weights/best.pt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames[:5]:  # cap at 5 per dir — Images/ has thousands of files\n",
    "        print(os.path.join(dirname, filename))\n",
    "    if filenames:\n",
    "        print(f'  ... ({len(filenames)} files total in {dirname})')\n",
    "        break  # stop after first dir with files to avoid flooding output\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import shutil\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Class mapping — normalise all XML name variants to 3 YOLO classes\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "CLASS_MAP: dict[str, tuple[int, str]] = {\n",
    "    # gun (index 0)\n",
    "    \"handgun\":    (0, \"gun\"),\n",
    "    \"Handgun\":    (0, \"gun\"),\n",
    "    \"pistol\":     (0, \"gun\"),\n",
    "    \"Pistol\":     (0, \"gun\"),\n",
    "    # rifle (index 1)\n",
    "    \"rifle\":      (1, \"rifle\"),\n",
    "    \"Rifle\":      (1, \"rifle\"),\n",
    "    \"short_rifle\":(1, \"rifle\"),\n",
    "    \"Short_rifle\":(1, \"rifle\"),\n",
    "    # knife (index 2)\n",
    "    \"knife\":      (2, \"knife\"),\n",
    "    \"Knife\":      (2, \"knife\"),\n",
    "    \"machete\":    (2, \"knife\"),\n",
    "}\n",
    "\n",
    "CLASSES = [\"gun\", \"rifle\", \"knife\"]\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Pascal VOC XML → YOLO txt\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def voc_to_yolo(xml_path: Path) -> list[str]:\n",
    "    \"\"\"Parse a Pascal VOC XML and return normalised YOLO label lines.\n",
    "    Returns [] for negative frames (no annotated objects).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "    except ET.ParseError:\n",
    "        return []\n",
    "\n",
    "    size = root.find(\"size\")\n",
    "    if size is None:\n",
    "        return []\n",
    "    w = float(size.findtext(\"width\") or 0)\n",
    "    h = float(size.findtext(\"height\") or 0)\n",
    "    if w == 0 or h == 0:\n",
    "        return []\n",
    "\n",
    "    lines = []\n",
    "    for obj in root.findall(\"object\"):\n",
    "        name = obj.findtext(\"name\", \"\").strip()\n",
    "        if name not in CLASS_MAP:\n",
    "            continue\n",
    "        cls_idx, _ = CLASS_MAP[name]\n",
    "\n",
    "        bndbox = obj.find(\"bndbox\")\n",
    "        if bndbox is None:\n",
    "            continue\n",
    "        xmin = float(bndbox.findtext(\"xmin\") or 0)\n",
    "        ymin = float(bndbox.findtext(\"ymin\") or 0)\n",
    "        xmax = float(bndbox.findtext(\"xmax\") or 0)\n",
    "        ymax = float(bndbox.findtext(\"ymax\") or 0)\n",
    "\n",
    "        xmin, xmax = max(0, xmin), min(w, xmax)\n",
    "        ymin, ymax = max(0, ymin), min(h, ymax)\n",
    "        if xmax <= xmin or ymax <= ymin:\n",
    "            continue\n",
    "\n",
    "        cx = ((xmin + xmax) / 2) / w\n",
    "        cy = ((ymin + ymax) / 2) / h\n",
    "        bw = (xmax - xmin) / w\n",
    "        bh = (ymax - ymin) / h\n",
    "        lines.append(f\"{cls_idx} {cx:.6f} {cy:.6f} {bw:.6f} {bh:.6f}\")\n",
    "\n",
    "    return lines\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Dataset assembly\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def collect_pairs(src_dir: Path) -> list[tuple[Path, Path]]:\n",
    "    \"\"\"Return (jpg_path, xml_path) pairs where both files exist.\"\"\"\n",
    "    pairs = []\n",
    "    for xml_path in sorted(src_dir.glob(\"*.xml\")):\n",
    "        jpg_path = xml_path.with_suffix(\".jpg\")\n",
    "        if jpg_path.exists():\n",
    "            pairs.append((jpg_path, xml_path))\n",
    "    print(f\"  {src_dir.name}: {len(pairs)} image/annotation pairs found\")\n",
    "    return pairs\n",
    "\n",
    "\n",
    "def convert_and_copy(\n",
    "    pairs: list[tuple[Path, Path]],\n",
    "    img_out_dir: Path,\n",
    "    lbl_out_dir: Path,\n",
    ") -> dict[str, int]:\n",
    "    \"\"\"Convert VOC XMLs to YOLO txts and copy images. Returns class counts.\"\"\"\n",
    "    img_out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    lbl_out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    counts = {\"pos\": 0, \"neg\": 0, **{c: 0 for c in CLASSES}}\n",
    "\n",
    "    for jpg_path, xml_path in pairs:\n",
    "        lines = voc_to_yolo(xml_path)\n",
    "        stem = f\"{xml_path.parent.name}_{xml_path.stem}\"\n",
    "        shutil.copy(jpg_path, img_out_dir / f\"{stem}.jpg\")\n",
    "        (lbl_out_dir / f\"{stem}.txt\").write_text(\"\\n\".join(lines))\n",
    "\n",
    "        if lines:\n",
    "            counts[\"pos\"] += 1\n",
    "            for line in lines:\n",
    "                counts[CLASSES[int(line.split()[0])]] += 1\n",
    "        else:\n",
    "            counts[\"neg\"] += 1\n",
    "\n",
    "    return counts\n",
    "\n",
    "\n",
    "def write_yaml(out_dir: Path, val_ratio: float = 0.1) -> Path:\n",
    "    \"\"\"Write YOLO dataset YAML with a random 90/10 train/val split.\"\"\"\n",
    "    img_dir = out_dir / \"images\" / \"all\"\n",
    "    all_imgs = list(img_dir.glob(\"*.jpg\"))\n",
    "    random.shuffle(all_imgs)\n",
    "\n",
    "    n_val = max(1, int(len(all_imgs) * val_ratio))\n",
    "    val_imgs   = all_imgs[:n_val]\n",
    "    train_imgs = all_imgs[n_val:]\n",
    "\n",
    "    for split_name, split_imgs in [(\"train\", train_imgs), (\"val\", val_imgs)]:\n",
    "        split_img_dir = out_dir / \"images\" / split_name\n",
    "        split_lbl_dir = out_dir / \"labels\" / split_name\n",
    "        split_img_dir.mkdir(parents=True, exist_ok=True)\n",
    "        split_lbl_dir.mkdir(parents=True, exist_ok=True)\n",
    "        for img in split_imgs:\n",
    "            lbl = (out_dir / \"labels\" / \"all\" / img.name).with_suffix(\".txt\")\n",
    "            dst_img = split_img_dir / img.name\n",
    "            dst_lbl = split_lbl_dir / img.with_suffix(\".txt\").name\n",
    "            if not dst_img.exists():\n",
    "                shutil.copy(img, dst_img)\n",
    "            if not dst_lbl.exists() and lbl.exists():\n",
    "                shutil.copy(lbl, dst_lbl)\n",
    "\n",
    "    yaml_path = out_dir / \"weapon.yaml\"\n",
    "    yaml_path.write_text(f\"\"\"\\\n",
    "path: {out_dir.resolve()}\n",
    "train: images/train\n",
    "val:   images/val\n",
    "\n",
    "nc: {len(CLASSES)}\n",
    "names: {CLASSES}\n",
    "\"\"\")\n",
    "    print(f\"  YAML: {yaml_path}\")\n",
    "    print(f\"  Train: {len(train_imgs)} images\")\n",
    "    print(f\"  Val:   {len(val_imgs)} images\")\n",
    "    return yaml_path\n",
    "\n",
    "print(\"Functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Paths — Kaggle read-only input on the left, preserved output on the right\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "IMAGES_DIR = Path(\"/kaggle/input/models/frankmurphy24/cctv-weapon-detector/other/default/1/Images\")\n",
    "OUT_DIR    = Path(\"/kaggle/working/weapon_dataset\")\n",
    "RUNS_DIR   = \"/kaggle/working/runs/weapon\"   # best.pt ends up here\n",
    "VAL_RATIO  = 0.1\n",
    "\n",
    "assert IMAGES_DIR.exists(), f\"Images directory not found: {IMAGES_DIR}\\nCheck that the dataset is attached to this notebook.\"\n",
    "print(f\"Images dir: {IMAGES_DIR}\")\n",
    "print(f\"Output dir: {OUT_DIR}\")\n",
    "print(f\"XML count:  {len(list(IMAGES_DIR.glob('*.xml')))}\")\n",
    "print(f\"JPG count:  {len(list(IMAGES_DIR.glob('*.jpg')))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Step 1 — Collect paired image/annotation files\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "print(\"=== STEP 1: Collect image/annotation pairs ===\")\n",
    "pairs = collect_pairs(IMAGES_DIR)\n",
    "print(f\"  Total: {len(pairs)} pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Step 2 — Convert Pascal VOC XML → YOLO txt, copy images to working dir\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "print(\"=== STEP 2: Convert Pascal VOC → YOLO ===\")\n",
    "out_img_dir = OUT_DIR / \"images\" / \"all\"\n",
    "out_lbl_dir = OUT_DIR / \"labels\" / \"all\"\n",
    "counts = convert_and_copy(pairs, out_img_dir, out_lbl_dir)\n",
    "print(f\"  Positive frames (with objects): {counts['pos']}\")\n",
    "print(f\"  Negative frames (no objects):   {counts['neg']}\")\n",
    "for cls in CLASSES:\n",
    "    print(f\"    {cls}: {counts[cls]} instances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Step 3 — Build 90/10 train/val split and write YOLO dataset YAML\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "print(\"=== STEP 3: Build train/val split ===\")\n",
    "yaml_path = write_yaml(OUT_DIR, VAL_RATIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Step 4 — Train YOLO11n (150 epochs, 640px, T4 GPU)\n",
    "# best.pt saved to /kaggle/working/runs/weapon/train/weights/best.pt\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "print(\"=== STEP 4: Train YOLO11n ===\")\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "model.train(\n",
    "    data=str(yaml_path),\n",
    "    epochs=150,\n",
    "    imgsz=640,\n",
    "    batch=64,\n",
    "    device=0,             # Kaggle T4 GPU\n",
    "    project=RUNS_DIR,\n",
    "    name=\"train\",\n",
    "    exist_ok=True,\n",
    "    # Augmentation tuned for CCTV: slight rotation, no vertical flip, colour jitter\n",
    "    hsv_h=0.015,\n",
    "    hsv_s=0.4,\n",
    "    hsv_v=0.5,\n",
    "    degrees=5,\n",
    "    flipud=0.0,\n",
    "    fliplr=0.5,\n",
    "    mosaic=1.0,\n",
    "    mixup=0.1,\n",
    "    copy_paste=0.1,\n",
    ")\n",
    "\n",
    "best = Path(RUNS_DIR) / \"train\" / \"weights\" / \"best.pt\"\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Training complete!\")\n",
    "print(f\"Best weights: {best}\")\n",
    "print(f\"\\nDownload best.pt from the Output tab, then:\")\n",
    "print(f\"  cp best.pt backend/models/weapon.pt\")\n",
    "print(f\"{'='*60}\")"
   ]
  }
 ]
}
